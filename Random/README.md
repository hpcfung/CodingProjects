## Similar projects

### 1
https://arxiv.org/abs/1905.02342

uses CNN + LSTM

https://research.nccgroup.com/2021/10/15/cracking-random-number-generators-using-machine-learning-part-1-xorshift128/

### 2
https://research.nccgroup.com/2021/10/15/cracking-random-number-generators-using-machine-learning-part-1-xorshift128/

similar project

## Results
- train loss goes down, but test loss goes up: overfitting? does not generalize
- ie it just memorizes the correct labels without developing an algorithm that can generalize?
- try autoencoder next? maybe it can pick up some good features?
